{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Mounting Drive"
      ],
      "metadata": {
        "id": "Cqywolj8b6BH"
      },
      "id": "Cqywolj8b6BH"
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/gdrive\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jc12lR9p5vfm",
        "outputId": "2ede3996-e3a0-40e4-cc88-ec321d287562"
      },
      "id": "Jc12lR9p5vfm",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importing Libraries"
      ],
      "metadata": {
        "id": "2Hh7ehkAbmlZ"
      },
      "id": "2Hh7ehkAbmlZ"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3166e9c1",
      "metadata": {
        "id": "3166e9c1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d0b75352-fb03-433c-f7fa-b0c0fb272633"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: mahotas in /usr/local/lib/python3.7/dist-packages (1.4.13)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from mahotas) (1.21.6)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorboardX in /usr/local/lib/python3.7/dist-packages (2.5.1)\n",
            "Requirement already satisfied: protobuf<=3.20.1,>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorboardX) (3.17.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from tensorboardX) (1.21.6)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf<=3.20.1,>=3.8.0->tensorboardX) (1.15.0)\n"
          ]
        }
      ],
      "source": [
        "##Importing Libraries\n",
        "from pylab import imshow, show\n",
        "import glob \n",
        "import time\n",
        "import os\n",
        "import logging\n",
        "import nibabel as nb\n",
        "import numpy as np\n",
        "import random as random\n",
        "from PIL import Image\n",
        "from matplotlib import cm\n",
        "from matplotlib import pyplot as plt\n",
        "from tqdm import tqdm\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import Dataset\n",
        "from torch import nn\n",
        "from torch.optim import Adam\n",
        "import torch\n",
        "import cv2\n",
        "from torchvision import models\n",
        "import torchvision\n",
        "!pip install mahotas\n",
        "import mahotas\n",
        "from torch.nn import functional as F\n",
        "from scipy import ndimage\n",
        "from torchvision import transforms\n",
        "!pip install tensorboardX\n",
        "from tensorboardX import SummaryWriter\n",
        "plt.style.use(\"dark_background\")\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preprocessing"
      ],
      "metadata": {
        "id": "oCXZ0sULbzdL"
      },
      "id": "oCXZ0sULbzdL"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "65c4fbcd",
      "metadata": {
        "id": "65c4fbcd"
      },
      "outputs": [],
      "source": [
        "IMG_PATH ='/content/gdrive/MyDrive/ISBD/'\n",
        "# CARE10 image labels missing so CARE10 train image removed\n",
        "train_images = []\n",
        "train_labels = []\n",
        "images_path = glob.glob(os.path.join(IMG_PATH,'train_images/','*'))\n",
        "labels_path = glob.glob(os.path.join(IMG_PATH,'train_labels/','*'))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "img = nb.load(images_path[0]).get_fdata()\n",
        "for i in range(len(images_path)):\n",
        "  for j in range(img.shape[0]):\n",
        "    im = Image.fromarray(nb.load(images_path[i]).get_fdata()[j,:,:]).convert('RGB')\n",
        "    im.save(\"/content/gdrive/MyDrive/Train_images/\"+str(i)+\"_\"+str(j)+\".jpeg\",\"Jpeg\")"
      ],
      "metadata": {
        "id": "dqy97zc4qZEX"
      },
      "id": "dqy97zc4qZEX",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7bdd769f",
      "metadata": {
        "id": "7bdd769f"
      },
      "outputs": [],
      "source": [
        "# def ImagetoMask(image):\n",
        "#     mask = Image.fromarray(np.uint8(cm.gist_earth(image)*255)).convert('RGB')\n",
        "#     mask = np.asarray(mask)\n",
        "#     return mask\n",
        "# def MasktoContour(image):\n",
        "#     gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "#     mask = Image.fromarray(np.uint8(cm.gist_earth(gray)*255))\n",
        "#     edged = cv2.Canny(gray, 30, 200)\n",
        "#     contours, hierarchy = cv2.findContours(edged,cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
        "#     contour_img = cv2.drawContours(image, contours, -1, (0, 255, 0), 1)\n",
        "#     return contour_img\n",
        "# def ContourtoDistanceMap(image):\n",
        "#     gaussian = mahotas.gaussian_filter(image, 15)\n",
        "#     gaussian = (gaussian > gaussian.mean())\n",
        "#     labeled, n_nucleus = mahotas.label(gaussian)\n",
        "#     dmap = mahotas.distance(labeled)\n",
        "#     return dmap"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "img = nb.load(images_path[0]).get_fdata()\n",
        "size = img.shape[0]\n",
        "for i in range(len(images_path)):\n",
        "  for j in range(size):\n",
        "    img = Image.fromarray(((nb.load(labels_path[i]).get_fdata()==2).astype(int)*255).astype(np.uint8)[j,:,:]).convert('L')\n",
        "    img.save(\"/content/gdrive/MyDrive/Train_Labels/Masks/\"+str(i)+\"_\"+str(j)+\".jpeg\",\"Jpeg\")\n",
        "    gaussian = mahotas.gaussian_filter(img,0.625)\n",
        "    gaussian = (gaussian > gaussian.mean())\n",
        "    labelled, n_nucleus = mahotas.label(gaussian)\n",
        "    relabeled = mahotas.labeled.bwperim(labelled, 8)\n",
        "    im = Image.fromarray(relabeled)\n",
        "    im.save(\"/content/gdrive/MyDrive/Train_Labels/Contours/\"+str(i)+\"_\"+str(j)+\".jpeg\",\"Jpeg\")\n",
        "    dmap = mahotas.distance(labelled)\n",
        "    plt.imsave(\"/content/gdrive/MyDrive/Train_Labels/Distance_Maps/\"+str(i)+\"_\"+str(j)+\".jpeg\",dmap)"
      ],
      "metadata": {
        "id": "jff5U8SKd7ii"
      },
      "id": "jff5U8SKd7ii",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # for i in range(len(labels_path)):\n",
        "# #   for j in range(img.shape[0]):\n",
        "# img = Image.fromarray(((nb.load(labels_path[6]).get_fdata()==2).astype(int)*255).astype(np.uint8)[91,:,:]).convert('L')\n",
        "# ims = ((nb.load(labels_path[6]).get_fdata()==2).astype(int)*255).astype(np.uint8)[91,:,:]\n",
        "# gaussian = mahotas.gaussian_filter(img,0.625)\n",
        "# gaussian = (gaussian > gaussian.mean())\n",
        "# labelled, n_nucleus = mahotas.label(gaussian)\n",
        "# relabeled = mahotas.labeled.bwperim(labelled, 8)\n",
        "# im = Image.fromarray(relabeled)\n",
        "# im\n",
        "# dmap = mahotas.distance(labelled)\n",
        "# plt.imsave(\"/content/gdrive/MyDrive/Train_Labels/Distance_Maps/test.jpeg\",dmap)"
      ],
      "metadata": {
        "id": "duniMZbhoDXK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 273
        },
        "outputId": "ed8e0a81-32a3-4800-8d72-53f14c25bc36"
      },
      "id": "duniMZbhoDXK",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=1 size=256x256 at 0x7F73BDFC83D0>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQAAAAEAAQAAAAB0CZXLAAAAZUlEQVR4nO3PKw6AMBQF0ccngERWsF6WxBJYDKoKBQTfitGEOa5kcksjJEmSJEmSfmgszm0ZDBkW0gIL6YAgXxDMPfxDGVQLU0Bwwg3RrbBw0yuioeChoP5S2KnfaEGSJEmS9HUvp4EKW0BPM1IAAAAASUVORK5CYII=\n"
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model"
      ],
      "metadata": {
        "id": "02ShHdU7yRMu"
      },
      "id": "02ShHdU7yRMu"
    },
    {
      "cell_type": "code",
      "source": [
        "PATH = \"/content/gdrive/MyDrive/\"\n",
        "train_images = []\n",
        "label_masks = []\n",
        "label_distance = []\n",
        "label_contour = []\n",
        "train_images = glob.glob(os.path.join(PATH,'Train_images','*'))\n",
        "# label_masks = glob.glob(os.path.join(PATH,'Train_Labels/Masks','*'))\n",
        "# label_distance = glob.glob(os.path.join(PATH,'Train_Labels/Distance_Maps','*'))\n",
        "# label_contour = glob.glob(os.path.join(PATH,'Train_Labels/Contours','*'))"
      ],
      "metadata": {
        "id": "uxFnkPPxyh7F"
      },
      "id": "uxFnkPPxyh7F",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(train_images))\n",
        "print(len(label_masks))\n",
        "print(len(label_distance))\n",
        "print(len(label_contour))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IWfkZSiw5XES",
        "outputId": "6d4d9bcd-38fb-466e-da9a-f0f6d5193fe8"
      },
      "id": "IWfkZSiw5XES",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "21696\n",
            "21696\n",
            "21696\n",
            "21696\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ec57af5f",
      "metadata": {
        "scrolled": true,
        "id": "ec57af5f"
      },
      "outputs": [],
      "source": [
        "class DatasetImageMaskContourDist(Dataset):\n",
        "\n",
        "    def __init__(self, train_images):\n",
        "\n",
        "        self.train_images = train_images\n",
        "\n",
        "    def __len__(self):\n",
        "\n",
        "        return len(self.train_images)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "\n",
        "        img_file_name = self.train_images[idx]\n",
        "        image = load_image(img_file_name)\n",
        "        mask = load_mask(img_file_name)\n",
        "        contour = load_contour(img_file_name)\n",
        "        dist = load_distance(img_file_name)\n",
        "\n",
        "        return img_file_name, image, mask, contour, dist\n",
        "\n",
        "\n",
        "def load_image(path):\n",
        "\n",
        "    img = Image.open(path)\n",
        "    data_transforms = transforms.Compose(\n",
        "        [\n",
        "            transforms.Resize(256),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
        "        ]\n",
        "    )\n",
        "    img = data_transforms(img)\n",
        "    # print(img.shape)\n",
        "    # img = img[0]\n",
        "\n",
        "    return img\n",
        "\n",
        "\n",
        "def load_mask(path):\n",
        "\n",
        "    mask = cv2.imread(path.replace(\"Train_images\", \"Train_Labels/Masks\"), 0)\n",
        "    mask[mask == 255] = 1\n",
        "\n",
        "    return torch.from_numpy(np.expand_dims(mask, 0)).long()\n",
        "\n",
        "\n",
        "def load_contour(path):\n",
        "\n",
        "    contour = cv2.imread(path.replace(\"Train_images\", \"Train_Labels/Contours\"), 0)\n",
        "    contour[contour == 255] = 1\n",
        "\n",
        "    return torch.from_numpy(np.expand_dims(contour, 0)).long()\n",
        "\n",
        "\n",
        "def load_distance(path):\n",
        "\n",
        "    dist = cv2.imread(path.replace(\"Train_images\", \"Train_Labels/Distance_Maps\"),0)\n",
        "\n",
        "    return torch.from_numpy(np.expand_dims(dist, 0)).float()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "69722977",
      "metadata": {
        "id": "69722977"
      },
      "outputs": [],
      "source": [
        "train, validate, test = np.split(train_images, [int(.6*len(train_images)), int(.8*len(train_images))])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ac68475d",
      "metadata": {
        "id": "ac68475d"
      },
      "outputs": [],
      "source": [
        "def conv3x3(in_, out):\n",
        "    return nn.Conv2d(in_, out, 3, padding=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bbb2083a",
      "metadata": {
        "id": "bbb2083a"
      },
      "outputs": [],
      "source": [
        "class Conv3BN(nn.Module):\n",
        "    def __init__(self, in_: int, out: int, bn=False):\n",
        "        super().__init__()\n",
        "        self.conv = conv3x3(in_, out)\n",
        "        self.bn = nn.BatchNorm2d(out) if bn else None\n",
        "        self.activation = nn.ReLU(inplace=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        if self.bn is not None:\n",
        "            x = self.bn(x)\n",
        "        x = self.activation(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a6312822",
      "metadata": {
        "id": "a6312822"
      },
      "outputs": [],
      "source": [
        "class UNetModule(nn.Module):\n",
        "    def __init__(self, in_: int, out: int):\n",
        "        super().__init__()\n",
        "        self.l1 = Conv3BN(in_, out)\n",
        "        self.l2 = Conv3BN(out, out)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.l1(x)\n",
        "        x = self.l2(x)\n",
        "        return"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "848ba421",
      "metadata": {
        "id": "848ba421"
      },
      "outputs": [],
      "source": [
        "class PsiNet(nn.Module):\n",
        "    output_downscaled = 1\n",
        "    module = UNetModule\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        input_channels: int = 3,\n",
        "        filters_base: int = 32,\n",
        "        down_filter_factors=(1, 2, 4, 8, 16),\n",
        "        up_filter_factors=(1, 2, 4, 8, 16),\n",
        "        bottom_s=4,\n",
        "        num_classes=1,\n",
        "        add_output=True,\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.num_classes = num_classes\n",
        "        assert len(down_filter_factors) == len(up_filter_factors)\n",
        "        assert down_filter_factors[-1] == up_filter_factors[-1]\n",
        "        down_filter_sizes = [filters_base * s for s in down_filter_factors]\n",
        "        up_filter_sizes = [filters_base * s for s in up_filter_factors]\n",
        "        self.down, self.up = nn.ModuleList(), nn.ModuleList()\n",
        "        self.down.append(self.module(input_channels, down_filter_sizes[0]))\n",
        "        for prev_i, nf in enumerate(down_filter_sizes[1:]):\n",
        "            self.down.append(self.module(down_filter_sizes[prev_i], nf))\n",
        "        for prev_i, nf in enumerate(up_filter_sizes[1:]):\n",
        "            self.up.append(\n",
        "                self.module(down_filter_sizes[prev_i] + nf, up_filter_sizes[prev_i])\n",
        "            )\n",
        "        pool = nn.MaxPool2d(2, 2)\n",
        "        pool_bottom = nn.MaxPool2d(bottom_s, bottom_s)\n",
        "        upsample1 = nn.Upsample(scale_factor=2)\n",
        "        upsample_bottom1 = nn.Upsample(scale_factor=bottom_s)\n",
        "        upsample2 = nn.Upsample(scale_factor=2)\n",
        "        upsample_bottom2 = nn.Upsample(scale_factor=bottom_s)\n",
        "        upsample3 = nn.Upsample(scale_factor=2)\n",
        "        upsample_bottom3 = nn.Upsample(scale_factor=bottom_s)\n",
        "\n",
        "        self.downsamplers = [None] + [pool] * (len(self.down) - 1)\n",
        "        self.downsamplers[-1] = pool_bottom\n",
        "        self.upsamplers1 = [upsample1] * len(self.up)\n",
        "        self.upsamplers1[-1] = upsample_bottom1\n",
        "        self.upsamplers2 = [upsample2] * len(self.up)\n",
        "        self.upsamplers2[-1] = upsample_bottom2\n",
        "        self.upsamplers3 = [upsample3] * len(self.up)\n",
        "        self.upsamplers3[-1] = upsample_bottom3\n",
        "\n",
        "        self.add_output = add_output\n",
        "        if add_output:\n",
        "            self.conv_final1 = nn.Conv2d(up_filter_sizes[0], num_classes, 1)\n",
        "        if add_output:\n",
        "            self.conv_final2 = nn.Conv2d(up_filter_sizes[0], num_classes, 1)\n",
        "        if add_output:\n",
        "            self.conv_final3 = nn.Conv2d(up_filter_sizes[0], 1, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        xs = []\n",
        "        print(len(self.downsamplers),len(self.down))\n",
        "        for downsample, down in zip(self.downsamplers, self.down):\n",
        "            print(\"x:\",x.shape)\n",
        "            x_in = x if downsample is None else downsample(xs[-1])\n",
        "            x_out = down(x_in)  #fix this one\n",
        "            print(x_out)\n",
        "            xs.append(x_out)\n",
        "            print(xs)\n",
        "\n",
        "        x_out = xs[-1]\n",
        "        x_out1 = x_out\n",
        "        x_out2 = x_out\n",
        "        x_out3 = x_out\n",
        "\n",
        "        # Decoder mask segmentation\n",
        "        for x_skip, upsample, up in reversed(\n",
        "            list(zip(xs[:-1], self.upsamplers1, self.up))\n",
        "        ):\n",
        "            x_out1 = upsample(x_out1)\n",
        "            x_out1 = up(torch.cat([x_out1, x_skip], 1))\n",
        "\n",
        "        # Decoder contour estimation\n",
        "        for x_skip, upsample, up in reversed(\n",
        "            list(zip(xs[:-1], self.upsamplers2, self.up))\n",
        "        ):\n",
        "            x_out2 = upsample(x_out2)\n",
        "            x_out2 = up(torch.cat([x_out2, x_skip], 1))\n",
        "\n",
        "        # Regression\n",
        "        for x_skip, upsample, up in reversed(\n",
        "            list(zip(xs[:-1], self.upsamplers3, self.up))\n",
        "        ):\n",
        "            x_out3 = upsample(x_out3)\n",
        "            x_out3 = up(torch.cat([x_out3, x_skip], 1))\n",
        "\n",
        "        if self.add_output:\n",
        "            x_out1 = self.conv_final1(x_out1)\n",
        "            if self.num_classes > 1:\n",
        "                x_out1 = F.log_softmax(x_out1, dim=1)\n",
        "\n",
        "        if self.add_output:\n",
        "            x_out2 = self.conv_final2(x_out2)\n",
        "            if self.num_classes > 1:\n",
        "                x_out2 = F.log_softmax(x_out2, dim=1)\n",
        "\n",
        "        if self.add_output:\n",
        "            x_out3 = self.conv_final3(x_out3)\n",
        "            x_out3 = F.sigmoid(x_out3)\n",
        "\n",
        "        return [x_out1, x_out2, x_out3]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a0556761",
      "metadata": {
        "id": "a0556761"
      },
      "outputs": [],
      "source": [
        "class LossMulti:\n",
        "    def __init__(\n",
        "        self, jaccard_weight=0, class_weights=None, num_classes=2, device=None\n",
        "    ):\n",
        "        self.device = device\n",
        "        if class_weights is not None:\n",
        "            nll_weight = torch.from_numpy(class_weights.astype(np.float32)).to(\n",
        "                self.device\n",
        "            )\n",
        "        else:\n",
        "            nll_weight = None\n",
        "\n",
        "        self.nll_loss = nn.NLLLoss(weight=nll_weight)\n",
        "        self.jaccard_weight = jaccard_weight\n",
        "        self.num_classes = num_classes\n",
        "\n",
        "    def __call__(self, outputs, targets):\n",
        "\n",
        "        targets = targets.squeeze(1)\n",
        "        loss = (1 - self.jaccard_weight) * self.nll_loss(outputs, targets)\n",
        "        if self.jaccard_weight:\n",
        "            eps = 1e-7\n",
        "            for cls in range(self.num_classes):\n",
        "                jaccard_target = (targets == cls).float()\n",
        "                jaccard_output = outputs[:, cls].exp()\n",
        "                intersection = (jaccard_output * jaccard_target).sum()\n",
        "\n",
        "                union = jaccard_output.sum() + jaccard_target.sum()\n",
        "                loss -= (\n",
        "                    torch.log((intersection + eps) / (union - intersection + eps))\n",
        "                    * self.jaccard_weight\n",
        "                )\n",
        "\n",
        "        return loss\n",
        "class LossPsiNet:\n",
        "    def __init__(self, weights=[1, 1, 1]):\n",
        "\n",
        "        self.criterion1 = LossMulti(num_classes=2)\n",
        "        self.criterion2 = LossMulti(num_classes=2)\n",
        "        self.criterion3 = nn.MSELoss()\n",
        "        self.weights = weights\n",
        "\n",
        "    def __call__(self, outputs1, outputs2, outputs3, targets1, targets2, targets3):\n",
        "\n",
        "        criterion = (\n",
        "            self.weights[0] * self.criterion1(outputs1, targets1)\n",
        "            + self.weights[1] * self.criterion2(outputs2, targets2)\n",
        "            + self.weights[2] * self.criterion3(outputs3, targets3)\n",
        "        )\n",
        "\n",
        "        return criterion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "65032d79",
      "metadata": {
        "id": "65032d79"
      },
      "outputs": [],
      "source": [
        "def build_model():\n",
        "    model = PsiNet(num_classes=2)\n",
        "    return model\n",
        "\n",
        "def train_model(model, targets, criterion, optimizer):\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    with torch.set_grad_enabled(True):\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(\n",
        "            outputs[0], targets[0]\n",
        "        )\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    return loss\n",
        "\n",
        "def define_loss(weights=[1, 1, 1]):\n",
        "\n",
        "    criterion = LossPsiNet(weights)\n",
        "\n",
        "    return criterion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1b482713",
      "metadata": {
        "id": "1b482713"
      },
      "outputs": [],
      "source": [
        "def evaluate(device, epoch, model, data_loader, writer):\n",
        "    model.eval()\n",
        "    losses = []\n",
        "    start = time.perf_counter()\n",
        "    with torch.no_grad():\n",
        "\n",
        "        for iter, data in enumerate(tqdm(data_loader)):\n",
        "\n",
        "            _, inputs, targets, _, _ = data\n",
        "            inputs = inputs.to(device)\n",
        "            targets = targets.to(device)\n",
        "            outputs = model(inputs)\n",
        "\n",
        "            loss = F.nll_loss(outputs[0], targets.squeeze(1))\n",
        "            losses.append(loss.item())\n",
        "\n",
        "        writer.add_scalar(\"Dev_Loss\", np.mean(losses), epoch)\n",
        "\n",
        "    return np.mean(losses), time.perf_counter() - start\n",
        "\n",
        "\n",
        "def visualize(device, epoch, model, data_loader, writer, val_batch_size, train=False):\n",
        "    def save_image(image, tag, val_batch_size):\n",
        "        image -= image.min()\n",
        "        image /= image.max()\n",
        "        grid = torchvision.utils.make_grid(\n",
        "            image, nrow=int(np.sqrt(val_batch_size)), pad_value=0, padding=25\n",
        "        )\n",
        "        writer.add_image(tag, grid, epoch)\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for iter, data in enumerate(tqdm(data_loader)):\n",
        "            _, inputs, targets, _, _ = data\n",
        "\n",
        "            inputs = inputs.to(device)\n",
        "\n",
        "            targets = targets.to(device)\n",
        "            outputs = model(inputs)\n",
        "\n",
        "            output_mask = outputs[0].detach().cpu().numpy()\n",
        "            output_final = np.argmax(output_mask, axis=1).astype(float)\n",
        "\n",
        "            output_final = torch.from_numpy(output_final).unsqueeze(1)\n",
        "\n",
        "            if train == \"True\":\n",
        "                save_image(targets.float(), \"Target_train\", val_batch_size)\n",
        "                save_image(output_final, \"Prediction_train\", val_batch_size)\n",
        "            else:\n",
        "                save_image(targets.float(), \"Target\", val_batch_size)\n",
        "                save_image(output_final, \"Prediction\", val_batch_size)\n",
        "\n",
        "            break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "de18e894",
      "metadata": {
        "id": "de18e894",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 536
        },
        "outputId": "14bd5f92-a6de-4639-f5e2-92ec86f341df"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-07-04 22:19,922 root INFO \n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\n",
            "  0%|          | 0/3255 [00:02<?, ?it/s]\n",
            "  0%|          | 0/1 [00:02<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5 5\n",
            "x: torch.Size([4, 3, 256, 256])\n",
            "None\n",
            "[None]\n",
            "x: torch.Size([4, 3, 256, 256])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-73-ba07cccb145b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     70\u001b[0m             \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtargets1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"loss\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-37-36b8a373a288>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, targets, criterion, optimizer)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_grad_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         loss = criterion(\n\u001b[1;32m     12\u001b[0m             \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-72-38290ec63d09>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mdownsample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdown\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownsamplers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdown\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"x:\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m             \u001b[0mx_in\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdownsample\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mdownsample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m             \u001b[0mx_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdown\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_in\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m#fix this one\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/pooling.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    162\u001b[0m         return F.max_pool2d(input, self.kernel_size, self.stride,\n\u001b[1;32m    163\u001b[0m                             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdilation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mceil_mode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m                             self.return_indices)\n\u001b[0m\u001b[1;32m    165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/_jit_internal.py\u001b[0m in \u001b[0;36mfn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    420\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mif_true\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    421\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 422\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mif_false\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    423\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mif_true\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mif_false\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36m_max_pool2d\u001b[0;34m(input, kernel_size, stride, padding, dilation, ceil_mode, return_indices)\u001b[0m\n\u001b[1;32m    795\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mstride\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    796\u001b[0m         \u001b[0mstride\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mannotate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 797\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_pool2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdilation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mceil_mode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    798\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    799\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: max_pool2d(): argument 'input' (position 1) must be Tensor, not NoneType"
          ]
        }
      ],
      "source": [
        "if __name__ == \"__main__\":\n",
        "\n",
        "    log_path = PATH + \"/summary\"\n",
        "    writer = SummaryWriter(log_dir=log_path)\n",
        "\n",
        "    logging.basicConfig(\n",
        "        filename=\"\".format(\"brain\"),\n",
        "        filemode=\"a\",\n",
        "        format=\"%(asctime)s,%(msecs)d %(name)s %(levelname)s %(message)s\",\n",
        "        datefmt=\"%Y-%m-%d %H:%M\",\n",
        "        level=logging.INFO,\n",
        "    )\n",
        "    logging.info(\"\")\n",
        "\n",
        "    random.shuffle(train)\n",
        "\n",
        "    device = torch.device(\"cpu\")\n",
        "\n",
        "    model = build_model()\n",
        "\n",
        "    if torch.cuda.device_count() > 1:\n",
        "        print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
        "        model = nn.DataParallel(model)\n",
        "\n",
        "    model = model.to(device)\n",
        "\n",
        "    # To handle epoch start number and pretrained weight\n",
        "    epoch_start = \"0\"\n",
        "    # if args.use_pretrained:\n",
        "    #     print(\"Loading Model {}\".format(os.path.basename(args.pretrained_model_path)))\n",
        "    #     model.load_state_dict(torch.load(args.pretrained_model_path))\n",
        "    #     epoch_start = os.path.basename(args.pretrained_model_path).split(\".\")[0]\n",
        "    #     print(epoch_start)\n",
        "\n",
        "    trainLoader = DataLoader(\n",
        "        DatasetImageMaskContourDist(train),\n",
        "        batch_size=4,\n",
        "    )\n",
        "    devLoader = DataLoader(\n",
        "        DatasetImageMaskContourDist(validate)\n",
        "    )\n",
        "    displayLoader = DataLoader(\n",
        "        DatasetImageMaskContourDist(validate),\n",
        "        batch_size=4,\n",
        "    )\n",
        "\n",
        "    optimizer = Adam(model.parameters(), lr=1e-4)\n",
        "    criterion = define_loss()\n",
        "\n",
        "    num_epochs = 1\n",
        "\n",
        "    for epoch in tqdm(\n",
        "        range(int(epoch_start) + 1, int(epoch_start) + 1 + num_epochs)\n",
        "    ):\n",
        "\n",
        "        global_step = epoch * len(trainLoader)\n",
        "        running_loss = 0.0\n",
        "\n",
        "        for i, (img_file_name, inputs, targets1, targets2, targets3) in enumerate(\n",
        "            tqdm(trainLoader)\n",
        "        ):\n",
        "\n",
        "            model.train()\n",
        "\n",
        "            inputs = inputs.to(device)\n",
        "            targets1 = targets1.to(device)\n",
        "            targets2 = targets2.to(device)\n",
        "            targets3 = targets3.to(device)\n",
        "\n",
        "            targets = [targets1, targets2, targets3]\n",
        "\n",
        "            loss = train_model(model, targets , criterion, optimizer)\n",
        "\n",
        "            writer.add_scalar(\"loss\", loss.item(), epoch)\n",
        "\n",
        "            running_loss += loss.item() * inputs.size(0)\n",
        "\n",
        "        epoch_loss = running_loss / len(train)\n",
        "\n",
        "        if epoch % 1 == 0:\n",
        "\n",
        "            dev_loss, dev_time = evaluate(device, epoch, model, devLoader, writer)\n",
        "            writer.add_scalar(\"loss_valid\", dev_loss, epoch)\n",
        "            visualize(device, epoch, model, displayLoader, writer, 4)\n",
        "            print(\"Global Loss:{} Val Loss:{}\".format(epoch_loss, dev_loss))\n",
        "        else:\n",
        "            print(\"Global Loss:{} \".format(epoch_loss))\n",
        "\n",
        "        logging.info(\"epoch:{} train_loss:{} \".format(epoch, epoch_loss))\n",
        "        if epoch % 5 == 0:\n",
        "            torch.save(\n",
        "                model.state_dict(), os.path.join(\"\", str(epoch) + \".pt\")\n",
        "            )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "30573509",
      "metadata": {
        "id": "30573509"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.4"
    },
    "colab": {
      "name": "Copy of Psi - Net.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}